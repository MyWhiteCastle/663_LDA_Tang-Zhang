{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to Real Data\n",
    "### About the Data\n",
    "The data that we will be using in this project is part of LDA-C, which is a C implementation of latent Dirichlet allocation (LDA). The data is composed of three parts: a 1.3-megabytes corpus of text documents, a standard list of stop words (words like \"the\", \"a\" and etc. that are supposed to be removed from being considered as words under topics), and a list of unique vocabularies that occur in the texts. The main corpus that we perform the analyses on comprises of 500 documents from the Associated Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampling Method\n",
    "First, we use the algorithm based on Gibbs sampling to accomplish our goal of summarizing 30 topics out of the 500 documents, and under each topic pick the top 10 words. This package is called \"LDApackage\". The final output is the file \"Gibbs_RD_topwords.dat\". $\\textbf{If wish to reproduce results, see README for instructions.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LDApackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'RealData.txt'\n",
    "pred = LDApackage.preprocessing(datafile)\n",
    "lda = LDApackage.LDAModel(pred)\n",
    "lda.estimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### To view the final output, please see \"topwords.dat\" in the directory. (Results would be rewritten each time running the code with different/same data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## VIEM Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get documents \n",
    "real_docs = LDApackage.read_documents('RealData.txt')\n",
    "#get topic and words\n",
    "alpha, log_beta, topicwords = LDApackage.LDA_VIEM(real_docs,10,10)\n",
    "\n",
    "#save topic words to txt file\n",
    "with open('VIEM_RD_topwords.txt', 'w') as f:\n",
    "    for item in topicwords:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For application on real data, the approximate time for Gibbs is about 3.5 minutes while for variational inference and EM algorithm, it takes about up to thirty minutes to run LDA_VIEM(). However, that does not necessaily mean that Gibbs overweighs EM. Reasons for the speed difference are many. For example, the actual implementation of Gibbs sampling heavily depends on the values of prior parameters and iteration numbers. The operation time would increase dramatically if we increase the iteration numbers for Gibbs sampling. VI-EM is robust on the other hand. In our implementation, we ignore the convergence condition but choose a fixed max iteration only. But in real case, both the convergence condition and a preset max iteration time ensure that the algorithm can handle large-scale data regardless of values of the inital hyperparameters.\n",
    "\n",
    "Real data results both exhibit some corroboration. The top 2 words for Topic 9 for Gibbs and topic 10 for VI-EM are both 'percent' and 'price'. From the top 10 words, we could easily infer that the topic is related to trade (which also mentions (gas) price).\n",
    "\n",
    "By closely examining the topics, we found that the topics from Gibbs are somewhat redudant. For example, in Gibbs sampling topic 3 and 4 both mention 'Soviet' and 'official(s)'/'officers'. On the other hand, VI EM gives 10 unique topics for the given 500 news.\n",
    "\n",
    "For the same topic, say topic 7 for Gibbs and topic 5 for VI-EM, the words vary a lot and intuitively VI-EM contains more unique words and yield more information. From topic 7 for Gibbs, we could only infer that the topic is related to some accident in school while from topic 5 for VI-EM, we could guess with confidence that it is related to some terrible accident in school with probably severe death because we see 'kill',\n",
    "'court','death' and 'hospit' as top words. VI-EM provides us with more meaningful information.  \n",
    "\n",
    "Benefiting from lemmatizing and stemming of words in word preprocessing part for VI-EM implementation, the corpus contains unique words which reduces inference and further contributes to word diversity. Doing word lemmatizing and stemming for Gibbs would also compenstate for some redundancy.\n",
    "\n",
    "Therefore, we conclude that VI-EM exhibits more diversity for topic-word distribution and is more robust in read-world scenario. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
